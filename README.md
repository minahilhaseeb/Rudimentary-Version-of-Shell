# Rudimentary-Version-of-Shell
#stsh — stanford shell
# *Learning Goals*
- To further advanced your multiprocessing system calls—e.g. *fork*, *waitpid*, *execvp*, etc.—as with *assign3*, but this time to manage arbitrarily large number of processes running different executables.
- To more fully understand pipes, pipelines, file redirection, *pipe2*, *open*, and *dup2*. 
- To gain practice with signals common to multiprocessing environments—specifically, *SIGCHLD*, *SIGINT*, and *SIGTSTP*.
- To synchronously manage signal delivery via *sigwait* and inline signal handers.
# Builtin stsh Commands
#### Your Assignment 4 shell needs to support a collection of builtin commands that should execute without creating any new processes.  The builtins are:
- *quit*, which exits the shell and abandons any jobs with at least one stopped or running process.  If there are any extra arguments after the *quit*, just can just ignore them.
- *exit*, which does the same thing as *quit*.  Extraneous arguments? Just ignore them.
- *fg*, which prompts a stopped job to continue in the foreground or brings a running background job into the foreground. *fg* takes a single job number (e.g. *fg* *3*).   If the provided argument isn't a number, there's no such job with that number, or the number of arguments isn't correct, then throw an *STSHException* around an actionable error message and allow your shell to carry on as if you never typed anything. 
- *bg*, which prompts a stopped job to continue in the background. *bg* takes a single job number (e.g. *bg* *3*).   If the provided argument isn't a number, there's no such job with that number, or the number of arguments isn't correct, then throw an *STSHException* around an actionable error message and allow your shell to continue like the error never happened. 
- *slay*, which is used to terminate a *single process* (which may have many sibling processes as part of a larger pipeline). *slay* takes either one or two numeric arguments.  If only one number is provided, it's assumed to be the pid of the process to be killed.  If two numbers are provided, the first number is assumed to be the job number, and the second is assumed to be a process index within the job.  So, *slay **12345* would terminate (in the *SIGKILL* sense of terminate) the process with pid 12345.  *slay 2 0* would terminate the first process in the pipeline making up job 2.  *slay 13 8* would terminate the 9th process in the pipeline of processes making up job 13.  If there are any issues (e.g., the arguments aren't numbers, or they are numbers but identify some nonexistent process, or the argument count is incorrect), then throw an *STSHException* around an actionable error message and allow your shell to just move on.
- *halt*, which has nearly the same story as *slay*, except that its one or two arguments identify a single process that should be halted (but not terminated) if it isn't already stopped.  If it's already stopped, then don't do anything and just return.
- *cont*, which has the same story as *slay* and *halt*, except that its one or two arguments identify a single process that should continue if it isn't already running.  When you prompt a single process to continue, you're asking that it do so in the background.
- *jobs*, which prints the job list to the console.  If there are any additional arguments, then just ignore them.

#### *Milestone 1:* 
- Descend into the *stsh-parser* directory, read through the *stsh-readline.h* and *stsh-parse.h* header files for data type definitions and function/method prototypes, type *make*, and play with the *stsh-parse-test* to gain a sense of what *readline* and the  *pipeline* constructor do for you.  
- In general, *readline* is like *getline*, except that you can use the your up- and down-arrow key to scroll through your input history (neat!). *pipeline* defines a bunch of fields that store all of the various commands that chain together to form a pipeline.  For example, the text *cat < /usr/include/stdio.h | wc > output.txt* would be split into two *command*s—one for the *cat* and a second for the *wc*—and populate the *vector<command>* in the pipeline with information about each of them. The *input* and *output* fields would each be nonempty, and the background field would be *false*.
#### *Milestone 2:* 
- Add code to *createJob* to get a pipeline of just one command (e.g. *stsh> sleep 5*) to run *in the foreground* until it's finished. You’ll need to construct an *argv* array on the stack, copying in the *command* and *tokens* from the first *command* in the pipeline. Rely on a  single call to *waitpid* to stall *stsh* until the process finishes.  .
#### *Milestone 3:* 
- Add support for pipelines consisting of *two* processes (i.e. binary pipelines like *cat /usr/include/stdio.h | wc*), and ensure that the standard output of the first is redirected to feed the standard input of the second.  The *pipeline* function from lecture (again, not to be confused with the *pipeline* data type) is a gesture to the basic pipeline functionality needed right here.  
- You’re going to want to fully understand the *pipe2* variant of *pipe*, since it’s of paramount importance for this milestone and even more so for the next.  Recall from lecture that the *O_CLOEXEC* flag we use with *pipe2* is short for *close* on *execvp*. When child processes call *execvp*, the file descriptors specifically created by *pipe2* will be closed automatically. This means you don’t need to worry about closing *pipe2*-generated file descriptors in the child processes (although closing them isn’t an error). You still, however, need to close *pipe2*-generated endpoints in the parent, since the parent’s thread of execution never leads directly to an *execvp*.
#### *Milestone 4:* 
- Read through *stsh-job-list.h*, *stsh-job.h*, and *stsh-process.h* to learn how to add a new foreground job to the job list and how to add processes to that job. Add code that does exactly that to the *stsh.cc* file, right after you successfully *fork* off the process . After your *waitpid* calls return, remove the job from the job list by setting the process’s state to *kTerminated* and calling *STSHJobList::synchronize*. 
#### *Milestone 5:* 
- Once you get your head around pipelines of one and two processes, work on getting *arbitrarily long pipeline chains* to do the right thing.  If, for example, the user types in *echo 12345 | ./conduit --delay 1 | ./conduit | ./conduit*, four processes are created, each with their own pid.  *echo*'s standard out feeds the standard in of the first *conduit*, whose standard out feeds into the standard in of the second *conduit*, which pipes its output to the standard input of the last *conduit*, which at last prints to the console. This will require some particularly clever work with *pipe2*, since a pipeline of, say, 11 processes needs to create 10 independent pipes.  Make sure you generalize the work you did for binary pipelines to ensure that the joblist is properly populates with *STSHJob* entries that themselves contain the correct number of *STSHProcess* entries.
#### *Milestone 6:* 
- Add support for input and output redirection via *<* and *>* (e.g. *cat < /usr/include/stdio.h | wc > output.txt*). The names of input and output redirection files are surfaced by the *pipeline* constructor, and if there is a nonempty string in the input and/or output fields of the pipeline record, that’s your signal that input redirection, output redirection, or both are needed.  Our *stsh* allows for input redirection to feed the standard input of the first process and for output redirection to collect the standard output of the last process. Other shells allow for more than that (e.g. in many shell, you can actually redirect input to feed the standard input of *any* process, overriding the piping), but our shell doesn’t.  Note, however, that for pipelines of length 1, the first and last process of the pipeline are the same.
- Make sure that all *open* calls are made in child processes. If the file you’re writing to doesn’t exist, create it (*O_CREAT*), and go with *0644* (with the leading zero) as the octal constant to establish the *rw-r--r--* permission. If the output file you’re redirecting to already exists, then truncate it using the *O_TRUNC* flag. Type *man 2 open* for the full report on *open* and a reminder of what flags can be bitwise-or’ed together for the second argument.
#### *Milestone 7:* 
- Until now, we’ve been allowing  *stsh* and all pipelines to run within the same *process group*.  However, it’s conventional to bundle all of the processes in any single job into their own group, separate from that surrounding the shell or any of the *other* jobs. This makes job control (e.g. ctrl-c, ctrl-z, *fg*, *bg*, etc.) easier, since you can send signals to an entire process group, which in turn sends signals to all processes within that group.
- In the same way that each process has its own process identifier, or *pid*, process groups get their own identifiers as well, although we call them process group ids, or *pgid*s. The operating system decides what the pids are, but we as programmers get to choose what the process group ids are.  By convention, however, shells set the pgid of a process group to be the same as the pid of its first child.  So, the pid of *echo* of, say, *echo 12345 | ./conduit | ./conduit | ./conduit* is generally established to be the pgid of the surrounding process group.
- You can decide which process group a particular process is assigned to by calling the sensibly named system call known as *setpgid*. *setpgid* takes two arguments: the first identifies a process id, and the second is the id of the process group the identified process should be placed in.  You’ll want to sift through *setpgid*’s man page for the details, but for the most part it’s very straightforward.  Here are some examples:
    * *setpgid(1000, 1000)* would place the process with pid 1000 into the process group with a pgid of 1000.  If the process group id’ed by 1000 doesn’t exist yet, then it’s created and pid 1000 becomes the group’s sole member.
    * *setpgid(1001, 1000)* places the process with pid of 1001 into an existing process group with pgid of 1000.  This is the type of call that might be made, for instance, when adding the second of two or more processes in a pipeline to the process group that will eventually contain all of them.
    * *setpgid(0, 0)* is a special case that’s equivalent to *setpgid(getpid(), getpid())*.
- As an example, if a pipeline consists of four processes with pids 4004, 4005, 4007, and 4008, they should all be placed in a process group with an ID of 4004. By doing this, you’ll be able to send signal to every process in a group using the *killpg* function, where the first argument is the process group id (e.g. *killpg(4004, SIGTSTP)*).  This will be important in later milestones, when we’ll be pleased that all of the processes in a single job/pipeline/group can be collectively identified by a single number.
- In order to avoid race conditions, you should redundantly call *setpgid* in the parent and the child for every child process. This redundancy is required if we’re to guarantee that all child processes be bundled in the same process group.
#### *Milestone 8:* 
- Add the ability to kill or pause a job by pressing ctrl-c or ctrl-z on the keyboard. If the shell receives *SIGINT* (ctrl+c) or *SIGTSTP* (ctrl-z) while a foreground job is running, it should forward the signal to the foreground process group. You can send a signal to a group using the *killpg(pgid, signal)* syscall.
- To do this, you’ll need to block *SIGINT* and *SIGTSTP* everywhere to prevent the shell from being killed or stopped, and block *SIGCHLD* everywhere while you’re at it so that these three signals can be delivered via *sigwait*.  Replace your *waitpid* calls from earlier and instead rely on the signal blocking, *sigwait*, and your ability to go in different directions for different signals.  The basic control flow should now look something like this:

while the foreground job is running (see STSHJobList::hasForegroundJob):
    wait for SIGINT, SIGTSTP, or SIGCHLD
    if SIGINT or SIGTSTP came in:
        forward the signal using killpg
    if SIGCHLD came in:
        loop:
            use waitpid to get the status of the child
            if waitpid returns something other than a valid pid, then break
            update the joblist as per the status info surfaced by waitpid

- You’ll need to update the third argument to *waitpid* so that your shell can pick up on child processes that stop or terminate. You should also be able to handle child processes that terminate unexpectedly (e.g. segfault).
- Also ensure that your code works for children that do not exit gracefully. You can test this with *./fpe 3*, which sleeps for 3 seconds and then crashes because of an intentional floating point exception, as with:
#### *Milestone 9:* 
- Make sure that if *SIGINT* or *SIGTSTP* come in while no foreground job is running (e.g. we’re displaying the shell prompt and waiting for user input), nothing happens. The shell should not exit or stop. Also, if you press ctrl+c at the shell prompt and then *sleep 12*, *sleep* should sleep for a full 12 seconds without immediately dying because of some tabled *SIGINT*. If you have a print statement when calling *killpg*, that print statement should not appear.
- Keep in mind that if *SIGINT* arrives while it is blocked, it will be added to the pending set and delivered when *sigwait* is called. If the user presses ctrl+c while the shell prompt is displayed, that will add *SIGINT* to the pending set, and then *SIGINT* will be delivered in *createJob*. Unfortunately, we don’t want that to happen, so to avoid this, we can clear *SIGINT* and *SIGTSTP* from the pending set before reaching the *sigwait* loop:
// Tell the OS we want to completely ignore SIGINT/SIGTSTP.  If these were
// already in the pending set, they will be removed.
signal(SIGINT, SIG_IGN);
signal(SIGTSTP, SIG_IGN);
// Allow SIGINT/SIGTSTP to come in again.  Assuming these signals are still
// blocked, they will be added to the pending set when they come in, and any
// calls to `sigwait` will retrieve them.
signal(SIGINT, SIG_DFL);
signal(SIGTSTP, SIG_DFL);
#### *Milestone 10:* 
- Implement the *fg* builtin, which takes a stopped process—stopped presumably because it was running in the foreground at the time you pressed ctrl-z—and prompts it to continue.  The *fg* builtin takes job number, translates that job number to a process group ID, and, if necessary, forwards a *SIGCONT* on to the process group via a call to *killpg(groupID, SIGCONT)*.  After sending *SIGCONT*, update the job state to *kForeground*, and then wait for the job to stop/terminate or for *SIGINT*/*SIGTSTP* to come in, same as you did in *createJob*. 
- Of course, if the argument passed to *fg* isn't a number, or it is but it doesn't identify a real job, then you should throw an *STSHException* that's wrapped around a clear error message saying so.  You should find the *parseNumber* function in *stsh-parse-utils* to be helpful.
#### * *Milestone 11:* 
- Now add support for background jobs. The *pipeline* constructor already searches for trailing *&*'s and records whether or not the pipeline should be run in the background in the *pipeline* struct. A background job should be run exactly the same as a foreground job, except you should pass *kBackground* to *joblist.addJob()*, and you should not use the *sigwait* loop to wait for the job to finish. (It’s running in the background, after all.) Also, when a pipeline is launched in the background your shell should print out a job summary that’s consistent with the following output:
*stsh**>* sleep 10 | sleep 10 | sleep 10 &
[1] 2744684 2744685 2744686
- We don’t provide code to print this, so you’ll have to print the job ID in square brackets and loop over the job’s processes to print the pids.  You’ll also want to ensure that the *fg* builtin brings a background process into the foreground and waits for its completion.
- Now, this introduces a complication: if we aren’t waiting for a foreground job to fall out of the foreground, then when do we update the job list? Well, the only time it’s truly important for the job list to be updated is when we are printing it, which happens when handling the *jobs* builtin.  In fact, we can have multiple background jobs running at the same time, so we might have any number of child processes that need an update.
- Before printing the job list, call *waitpid* repeatedly to get any incidental status updates. You can’t call *waitpid* normally as you did earlier in the assignment, because if all child processes are running and haven’t had any state changes, then *waitpid* will block and we won’t print out the job list until a child stops/continues/terminates.  But if we add the *WNOHANG* flag to *waitpid*, then *waitpid* will check if child processes have had state changes without waiting for them.  If some children have had state changes (i.e. we want to update the job list), *waitpid* will return the pid of one such child; if no children have changed state, it will immediately return 0 without blocking.  (Some of you may have relied on *WNOHANG* in earlier milestones thinking you needed it, and if you did, that’s perfectly fine.)
- With all of this in mind, we can write something like the following:

loop:
    call waitpid with WNOHANG and any other additional flags
    if waitpid returned 0 or -1, there are no more updates, so break out of the loop
    update the child's status in the job list
- And we’re not quite done with this milestone yet! When the user invokes either the *quit* or *exit* builtins, you should be sure to reap any zombie processes that quietly finished in the background before you truly exit.  It’s possible there are some background jobs that haven’t completed, and you can ignore those knowing that the OS will adopt them as its own. But if you can identify any zombies and cull them before exiting, you should be that upstanding shell citizen and make sure you call *waitpid* on them.
- While doing all of this, be sure to consolidate any common code you previously wrote for *createJob* and *fg*.  *In fact, you ultimately should only have one ** waitpid ** call in all of your code.* With background processes involved, it’s crucial that you call *waitpid* on pid *-1* with *WNOHANG* even in *createJob* and *fg*, because otherwise, *SIGCHLD* signals generated from background processes might cause you to call *waitpid* when waiting for the foreground job to finish, and if you haven’t done this properly, your shell will block on *waitpid* and ignore any incoming *SIGINT*/*SIGTSTP* signals.
#### *Milestone 12:* 
- Add support for the *bg* command, which is almost identical to *fg* but continues a stopped job to run in the background. Then add support for *slay*, *halt*, *cont*, which send *SIGKILL*, *SIGTSTP*, and *SIGCONT* to a single process (as opposed to *fg* and *bg*, which send signals to process groups). Be sure to unify as much code as possible, and be sure to guard against errors in user input.  You shouldn’t need to update the job list for these builtins. It’s unnecessary, and keep in mind that sending *SIGTSTP* isn’t even guaranteed to stop the process. Instead, let the *jobs* builtin take care of updating the list.
#### *Milestone 13:* 
- Finally, you need to restore some basic functionality that likely broke when you introduced process grouping.  In particular, it’s likely that typing in something as simple as emacs or vim will elicit all types of weirdness.  In order for programs like emacs to run properly, they need control of the terminal.  Unfortunately, only one process group can control the terminal at any one point, and by default, the process group that is your shell owns in.  In general, the process group you’re interacting with at any one moment should have control of the terminal.  That means where you’re typing in commands at the *stsh>* prompt, *stsh* should control the terminal. But when the shell is stalled and waiting on a foreground job, the process group linked to that job should control the terminal instead. 
- You should investigate the *tcsetpgrp* function as a way of transferring terminal control back and forth between process groups.  When *tcsetpgrp(STDIN_FILENO, pgid)* succeeds, then it returns 0. If it fails, it returns -1.  When *tcsetpgrp* returns -1, you should throw an *STSHException*, since neither the shell nor the foreground process can be expected to work properly if they don’t have control of the terminal.
#### Update your solution to manage these two details:
- call *tcsetpgrp* from the first child process in a foreground job.  And after that foreground job has fallen out of the foreground (e.g. it exits or stops), use - tcsetpgrp* to transfer control back to the shell.
- call *tcsetpgrp* in response to your *fg* built-in to transfer control of the terminal to the soon-to-be foreground job before actually continuing it.  When foreground jobs created by *fg* ultimately fall out of the foreground, transfer control of the terminal back to the shell.  
#### Other Requirements*
- Your implementation should be in C++ unless there's no way to avoid it. By that, I mean you should use *C++* strings unless C strings are required, use *cout* instead of *printf*, and so forth.
- We have reasonably low expectations on error checking for this assignment, but we do have some.  We want you to focus on how to leverage system directives to get a fully functional shell working, but we don't want you to examine the return value of a system call when it's more or less impossible for it to fail.  In general, any error checking should guard against *user* error—attempts to invoke a nonexistent executable, providing out-of-range arguments to command-line built-ins, and so forth.  Very occasionally, you *do* need to check the return value of a system call or two, because sometimes system call "failure" (the air quotes are intentional) isn't a true failure.  You've seen situations where *waitpid* returns -1 even though everything was fine, and that happens with a few other system calls as well.
- All unused file descriptors should be closed.
- You do not need to support pipelines or redirection for any of the builtins.  In principle, you should be able to, say, redirect the output of *jobs* to a file, or pipe the output to another process, but you don't need to worry about this for Assignment 4. Our tests will never mix builtins with pipes/redirection.
- Don’t worry about executables like *emacs* and *vim* and how they behave unless they are purely standalone (e.g. *emacs* at the prompt, and that’s it).  As soon as you expect such executables to work with pipelines and redirection or run in the background, there’s no well-defined behavior to code to.
- When an entire pipeline is run as a background job, make sure you print out a job summary that's consistent with the following output:
*stsh**>* sleep 10 | sleep 10 | sleep 10 &
[1] 1398339 1398340 1398341
